<h1>Rei Sato</h1>

<h2>About</h2>
<ul>
  <li>筑波大学 情報科学類</li>
</ul>

<h2>読んだやつ</h2>
<ol>
  <li>Xception: Deep Learning with Depthwise Separable Convolutions</li>
  <li>SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model</li>
  <li>ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation</li>
  <li>Model Compression</li>
  <li>Distilling the Knowledge in a Neural Network</li>
  <li>Do Deep Nets Really Need to be Deep?</li>
  <li>Face Model Compression by Distilling Knowledge from Neurons</li>
  <li>Reducing the Model Order of Deep Neural Networks Using Information Theory</li>
  <li>Optimal Brain Damage</li>
  <li>Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding</li>
  
  <li>BinaryConnect: Training Deep Neural Networks with binary weights during propagations</li>
  <li>Binarized Neural Networks: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1</li>
  <li>XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks</li>
  <li>An Exploration of Parameter Redundancy in Deep Networks with Circulant Projections</li>
  <li>Predicting Parameters in Deep Learning</li>
  <li>Restructuring of Deep Neural Network Acoustic Models with Singular Value Decomposition</li>
  <li>Compressing Neural Networks with the Hashing Trick</li>
  <li>Compression of Deep Convolutional Neural Networks for Fast and Low Power Mobile Applications</li>
  <li>Speeding up Convolutional Neural Networks with Low Rank Expansions</li>
  <li>Learning Separable Filters</li>
  
  
</ol>
