<h1>l</h1>
<ol>
  <li>Xception: Deep Learning with Depthwise Separable Convolutions</li>
  <li>SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model</li>
  <li>ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation</li>
  <li>Model Compression</li>
  <li>Distilling the Knowledge in a Neural Network</li>
  <li>Do Deep Nets Really Need to be Deep?</li>
  <li>Face Model Compression by Distilling Knowledge from Neurons</li>
  <li>Reducing the Model Order of Deep Neural Networks Using Information Theory</li>
  <li>Optimal Brain Damage</li>
  <li>Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding</li>
  
  <li>BinaryConnect: Training Deep Neural Networks with binary weights during propagations</li>
  <li>Binarized Neural Networks: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1</li>
  <li>XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks</li>
  <li>An Exploration of Parameter Redundancy in Deep Networks with Circulant Projections</li>
  <li>Predicting Parameters in Deep Learning</li>
  <li>Restructuring of Deep Neural Network Acoustic Models with Singular Value Decomposition</li>
  <li>Compressing Neural Networks with the Hashing Trick</li>
  <li>Compression of Deep Convolutional Neural Networks for Fast and Low Power Mobile Applications</li>
  <li>Speeding up Convolutional Neural Networks with Low Rank Expansions</li>
  <li>Learning Separable Filters</li>
  
  
  <li>Sparsifying Neural Network Connections for Face Recognition</li>
  <li>Optimal Brain Surgeon and general network pruning</li>
  <li>Structured Transforms for Small-Footprint Deep Learning</li>
  <li>Deep Fried Convnets</li>
  <li>Fast Algorithms for Convolutional Neural Networks</li>
  <li>cuDNN: Efficient Primitives for Deep Learning</li>
  <li>MEC: Memory-efficient Convolution for Deep Neural Network</li>
  <li>MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications</li>
  <li>Flattened Convolutional Neural Networks for Feedforward Acceleration</li>
  <li>Accelerating Very Deep Convolutional Networks for Classification and Detection (Efficient and Accurate Approximations of Nonlinear Convolutional Networks)</li>
  
  
  <li>Speeding-up Convolutional Neural Networks Using Fine-tuned CP-Decomposition</li>
  <li>Exploiting Linear Structure Within Convolutional Networks for Efficient Evaluation</li>
  <li>Convolutional Neural Networks at Constrained Time Cost</li>
  <li>Quantized Convolutional Neural Networks for Mobile Devices</li>
  <li>Design of Efficient Convolutional Layers using Single Intra-channel Convolution, Topological Subdivisioning and Spatial “Bottleneck” Structure</li>
  <li>Training CNNs with Low-Rank Filters for Efficient Image Classification</li>
  <li>Convolutional neural networks with low-rank regularization</li>
  <li>FitNets: Hints for Thin Deep Nets</li>
  <li>Fast ConvNets Using Group-wise Brain Damage</li>
  <li>LCNN: Lookup-based Convolutional Neural Network</li>
  
  
</ol>
