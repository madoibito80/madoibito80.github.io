<h1>Rei Sato</h1>

<h2>About</h2>
<ul>
  <li>College of Information Science, University of Tsukuba</li>
</ul>

<h2>...</h2>
<ol>
  <li>Xception: Deep Learning with Depthwise Separable Convolutions</li>
  <li>SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model</li>
  <li>ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation</li>
  <li>Model Compression<li>
  <li>Distilling the Knowledge in a Neural Network<li>
  <li>Do Deep Nets Really Need to be Deep?<li>
  <li>Face Model Compression by Distilling Knowledge from Neurons<li>
  <li>Reducing the Model Order of Deep Neural Networks Using Information Theory<li>
  <li>Optimal Brain Damage<li>
  <li>Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding<li>
</ol>
